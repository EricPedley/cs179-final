{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2035e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Warning: Missing ground truth pose for interval 1585067782.1078572 to 1585067782.140857. Skipping this interval.\n",
      "Warning: Missing ground truth pose for interval 1585067782.140857 to 1585067782.1738572. Skipping this interval.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data_reading import read_images, load_reference_poses, read_imu, sync_data\n",
    "from visualization import visualize_trajectory\n",
    "from visual_odometry import compute_relative_pose, compute_matches, add_vo_factors\n",
    "from imu_preintegration import add_imu_factors\n",
    "\n",
    "imgs = read_images()\n",
    "imu = read_imu()\n",
    "gt_poses = load_reference_poses()\n",
    "imgs_list = []\n",
    "for i, img in enumerate(imgs):\n",
    "    if i>1000:\n",
    "        break\n",
    "    imgs_list.append(img)\n",
    "synced_data = sync_data(imu, imgs_list, gt_poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ce354c-da64-426b-abdf-f33895ae0bb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The threshold is not set for the MAGSAC scoring object.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 100\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m avg_pos_error, avg_rot_error\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m \u001b[43mcreate_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 46\u001b[0m, in \u001b[0;36mcreate_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m ground_truth\u001b[38;5;241m.\u001b[39mappend(data\u001b[38;5;241m.\u001b[39mgt_pose_start)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m     \u001b[43madd_vo_factors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_estimates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpose_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpose_count\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeypoint_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     pose_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39merror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Desktop/cs179-final-3/visual_odometry.py:232\u001b[0m, in \u001b[0;36madd_vo_factors\u001b[0;34m(g, data, initial_values, pose_variable_indices, keypoint_data, first, insert_initial_pose_values)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;124;03m1: compute keypoints matches and relative pose between images\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;124;03m2. get pose estimate of first image from graph\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03mmutates `g` and `keypoint_data` to add new factors and landmarks\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# 1:\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m vo_points0, vo_points1, vo_descriptors, vo_E \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_matches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_left_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_left_end\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m vo_t, vo_r \u001b[38;5;241m=\u001b[39m compute_relative_pose(vo_E, vo_points0, vo_points1)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# vo_t = np.zeros(3)\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# vo_r = Rotation.identity()\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# 2:\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/cs179-final-3/visual_odometry.py:124\u001b[0m, in \u001b[0;36mcompute_matches\u001b[0;34m(img1, img2)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Order by the score\u001b[39;00m\n\u001b[1;32m    122\u001b[0m splg_matches \u001b[38;5;241m=\u001b[39m splg_matches[\u001b[38;5;241m0\u001b[39m][np\u001b[38;5;241m.\u001b[39margsort(splg_matches[\u001b[38;5;241m1\u001b[39m])[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]], np\u001b[38;5;241m.\u001b[39msort(splg_matches[\u001b[38;5;241m1\u001b[39m])[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 124\u001b[0m E, inliers, score, iterations \u001b[38;5;241m=\u001b[39m \u001b[43mpysuperansac\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimateEssentialMatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mascontiguousarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplg_matches\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mimg1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((splg_matches[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m    133\u001b[0m mask[inliers] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The threshold is not set for the MAGSAC scoring object."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import gtsam\n",
    "from pyLSHash import LSHash\n",
    "from gtsam import DoglegOptimizer, Values, symbol_shorthand\n",
    "from imu_preintegration import init_preint_params, init_imu_bias, add_gt_pose_nodes\n",
    "L = symbol_shorthand.L\n",
    "X = symbol_shorthand.X\n",
    "\n",
    "def create_graph():\n",
    "    #Noise on prior pose - pretty confident\n",
    "    PRIOR_NOISE = gtsam.noiseModel.Diagonal.Sigmas(\n",
    "        np.array([0.05, 0.05, 0.05, 0.01, 0.01, 0.01])\n",
    "    )\n",
    "    initial_estimates = Values()\n",
    "    graph = gtsam.NonlinearFactorGraph()\n",
    "\n",
    "    #Converting pose into Pose3 object that GTSAM can use\n",
    "    pos = synced_data[0].gt_pose_start[0]\n",
    "    rot = synced_data[0].gt_pose_start[1]\n",
    "    R = rot.as_matrix()\n",
    "    rot3 = gtsam.Rot3(R)\n",
    "    point3 = gtsam.Point3(pos[0], pos[1], pos[2])\n",
    "    pose3 = gtsam.Pose3(rot3, point3)\n",
    "    #Using starting pose as PriorFactor\n",
    "    graph.add(gtsam.PriorFactorPose3(X(0), pose3, PRIOR_NOISE))\n",
    "    \n",
    "    pose_count = 0\n",
    "    \n",
    "    keypoint_data = LSHash(\n",
    "            hash_size=32,\n",
    "            input_dim=256,\n",
    "            num_hashtables=1,\n",
    "    )\n",
    "    initial_estimates.insert(X(0), gtsam.Pose3())\n",
    "    # add_gt_pose_nodes(graph, synced_data, initial_estimates)\n",
    "    #Iterate through synced data and call factor functions on each data point\n",
    "    preint_params = init_preint_params()\n",
    "    preint_bias = init_imu_bias()\n",
    "    ground_truth = []\n",
    "    for data in synced_data:\n",
    "        ground_truth.append(data.gt_pose_end)\n",
    "        ground_truth.append(data.gt_pose_start)\n",
    "        \n",
    "        try:\n",
    "            add_vo_factors(graph, data, initial_estimates, (pose_count,pose_count+1), keypoint_data)\n",
    "            pose_count +=1\n",
    "        except cv2.error as e:\n",
    "            if \"five-point.cpp\" in str(e) and \"npoints >= 0\" in str(e):\n",
    "                print(f\"Skipping frame pair {pose_count}-{pose_count+1} due to insufficient correspondences.\")\n",
    "                continue\n",
    "            else:\n",
    "                raise \n",
    "    add_imu_factors(graph, synced_data, initial_estimates, preint_params, preint_bias)\n",
    "    #Run graph through Dogleg Optimizer \n",
    "    #print(initial_estimates)\n",
    "    params = gtsam.DoglegParams()\n",
    "    #Debugging statement\n",
    "    params.setVerbosity(\"TERMINATION\")\n",
    "    optimizer = DoglegOptimizer(graph, initial_estimates, params)\n",
    "    result = optimizer.optimize()\n",
    "    result.print(\"Final results:\\n\")\n",
    "    estimates = []\n",
    "    for i in range(pose_count):\n",
    "        key = symbol('x', i)\n",
    "        if result.exists(key):\n",
    "            pose = result.atPose3(key)\n",
    "            pos = np.array([pose.x(), pose.y(), pose.z()])\n",
    "            rot = Rotation.from_matrix(pose.rotation().matrix())\n",
    "            estimates.append(pos, rot)\n",
    "    avg_pos_error, avg_rot_error = compare_error(estimates, ground_truth)\n",
    "    print(avg_pos_error, avg_rot_error)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compare_error(estimates, real_values):\n",
    "    min_length = min(len(estimates), len(real_values))\n",
    "    pos_errors = []\n",
    "    rot_errors = []\n",
    "    for ind in range(min_length):\n",
    "        real_pos, real_rot = real_values[ind].gt_pose_end\n",
    "        e_pos, e_rot = estimates[ind].gt_pose_end\n",
    "        pos_diff = real_pos - e_pos\n",
    "        pos_error = np.linalg.norm(pos_diff)\n",
    "        euler_real = real_rot.as_euler('XYZ', degrees=True)\n",
    "        euler_estimate = e_rot.as_euler('XYZ', degrees=True)\n",
    "        rot_error = np.linalg.norm(euler_real - euler_estimate)\n",
    "        pos_errors.append(pos_error)\n",
    "        rot_errors.append(rot_error)\n",
    "    if min_length:\n",
    "        avg_pos_error = sum(pos_errors) / len(pos_errors)\n",
    "        avg_rot_error = sum(rot_errors) / len(rot_errors)\n",
    "        return avg_pos_error, avg_rot_error\n",
    "    return None, None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "create_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a553f9d7-39d5-42f3-ade2-e374d0e955e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
